{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting started with the Event Based Model\n",
    "## Author: Neil Oxtoby, UCL (conversion to RISE by David Cash)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives:\n",
    "\n",
    "At the end of this notebook, you will be have learned how to fit an event-based model of disease progression based on simulated data. After going through this notebook, you should have the knowledge to set up the EBM for your data in the project notebook.\n",
    "\n",
    "* For more information, please see the [Disease Progression Modelling website](https://disease-progression-modelling.github.io)\n",
    "* Code and notebooks taken from the [KDE-EBM Github repository](https://github.com/ucl-pond/kde_ebm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup \n",
    "The steps for performing an EBM analysis typically involve:\n",
    "- Load input data: usually in some tabular format (i.e. a spreadsheet)\n",
    "- Identify which features to use\n",
    "- Determine probability distributions for abnormality in each feature\n",
    "- Fit the event-based model\n",
    "- Perform cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First import some packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18}) # default fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulated data - Patients\n",
    "* 100 patients, where we know their \"actual\" time from onset. \n",
    "  * Patients are evenly spaced out from 0 (onset of AD) to 20 years after onset \n",
    "* Four features: 0 represents normal, 1 abnormal\n",
    "  * Patients follow a sigmoidal transition from normal to abnormal\n",
    "* Matrix of features will be stored in two-dimensional matrix `X_patients` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Define some key parameters for our simulated data\n",
    "num_features = 4   # number of events/features\n",
    "num_patients = 100 # number of patients\n",
    "disease_duration = 20 # Number of years \n",
    "noise_scale = 0.1 # Amount of noise in the biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the colors of the plot so points and lines can be the same. \n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "# List of dictionaries for key plotting information of each biomarker\n",
    "# Notice the onset changes, Biomarker 1 starts at year 4, biomarker 2 @ year 8, etc)\n",
    "feature_info = [\n",
    "    { 'label': 'Biomarker 1', 'id': 0, 'gradient': 1, 'onset': 4, 'color': colors[0]},\n",
    "    { 'label': 'Biomarker 2', 'id': 1, 'gradient': 1, 'onset': 8, 'color': colors[1]},\n",
    "    { 'label': 'Biomarker 3', 'id': 2, 'gradient': 1, 'onset': 12, 'color': colors[2]},\n",
    "    { 'label': 'Biomarker 4', 'id': 3, 'gradient': 1, 'onset': 16, 'color': colors[3]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The lambda command in Python\n",
    "* The `lambda` keyword is a way to define a quick function in-line that you want to re-use later in the program.\n",
    "* Here we are going to use it to create sigmoidal functions to simulate the trajectory of each biomarker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sigmoid function: t, a, b - are the parameters that are passed as inputs\n",
    "# a and b have default values\n",
    "sigmoid = lambda t, a=1, b=-10 : 1/(1 + np.exp(-a*(t-b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# np.linspace makes a vector with evenly spaced increments from start (0)\n",
    "# to end (disease_duration=20) with the total number of increments specified as the number of patients (100)\n",
    "disease_time = np.linspace(0, disease_duration, num_patients)\n",
    "\n",
    "# Creates the two dimensional matrix holding the features of each patient\n",
    "X_patients = np.empty(shape=(num_patients,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Create a figure\n",
    "fig,ax = plt.subplots(figsize=(10,5))    \n",
    "# Loop through each feature, plotting the feature along the way\n",
    "for feature in feature_info:\n",
    "    id = feature['id']\n",
    "    x = sigmoid(t=disease_time,a=feature['gradient'],b=feature['onset'])  # ideal value of sigmoid\n",
    "    ax.plot(disease_time, x, c=feature['color'])\n",
    "    X_patients[:,id] = x + np.random.normal(0, noise_scale, num_patients) # sigmoid plus noise\n",
    "    ax.plot(disease_time, X_patients[:,id],'.',label=feature['label'])\n",
    " \n",
    "ax.set_xlabel(\"Disease Progression Time\",fontsize=20) \n",
    "ax.set_ylabel(\"Biomarker Value\",fontsize=20)\n",
    "ax.legend(bbox_to_anchor=(1.02, 0.5),loc=\"center left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulated data - Controls\n",
    "* The same four features measured as patients\n",
    "* For simplicity, the same number of controls (100) as patients\n",
    "* None of the controls will have abnormal values, just some random noise around zero. \n",
    "* We will store this matrix of observations in `X_controls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#* Sample some controls\n",
    "X_controls = np.empty(shape=X_patients.shape)\n",
    "for k in range(num_features):\n",
    "    X_controls[:,k] = np.random.normal(0, noise_scale, num_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review the simulated data\n",
    "\n",
    "### Visual inspection of feature distributions\n",
    "\n",
    "* Does the feature relate to the disease process? No use including it if not abnormal\n",
    "* Let's first *look at the data* by visually checking the feature's distribution in our patient group and control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#* Plot histogram for each feature\n",
    "nrows = int(num_features/2)\n",
    "ncols = 2\n",
    "fig,ax = plt.subplots(nrows, ncols,figsize=(12,7))\n",
    "for k in range(num_features):\n",
    "    plt_row = int(np.floor(k/2))\n",
    "    plt_col = k % 2\n",
    "    ax[plt_row, plt_col].hist([ X_patients[:,k],X_controls[:,k]],label=['Patients','Controls'])\n",
    "    ax[plt_row, plt_col].set_title('Biomarker %i' % (k+1),fontsize=16)\n",
    "ax[0,1].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic statistical tests\n",
    "* Null hypothesis: there are no \"differences\" between groups.\n",
    "* Non-parametric Mann-Whitney U test to assess a feature's ability to discriminate between patients and controls\n",
    "  * No assumption about the underlying distribution\n",
    "* P-value: the probability that the null hypothesis is true given the data\n",
    "* Effect size: (difference in medians between groups) / (\"width\" of controls distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print('Mann Whitney U test')\n",
    "# Loop through features\n",
    "for k in range(num_features):\n",
    "    x_c = X_controls[:,k]\n",
    "    x_p = X_patients[:,k]\n",
    "    effect_size = np.absolute(np.median(x_p)-np.median(x_c))/stats.median_abs_deviation(x_c)\n",
    "    u,p = stats.mannwhitneyu(x_c,x_p)\n",
    "    print('Biomarker %i\\n - effect size = %.3g\\n - u = %i, p = %.2g' % (k+1,effect_size,u,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* All four statistical tests show substantial evidence of a difference between patients and controls\n",
    "  * So they can all be included in the EBM!\n",
    "* Biomarkers that have earlier onset show the most abnormal values and thus the largest effect sizes (and lowest p-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare data for analysis with EBM\n",
    "* Let's organise the data in a structure that is ready for use in the EBM package. \n",
    "* Combine patient feature matrix `X_patients` with matrix for controls `X_controls` into `X_combined`\n",
    "* We also need to assign *labels* to tell the EBM who are patients and who are controls\n",
    "  * Stored in `y_patients` and `y_controls` and then combined into `Y_combined` \n",
    "* This combination is achieved by vertically stacking one matrix on top of the other using numpy's `concatenate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#* Setup data for fitting\n",
    "y_patients = np.ones(shape=(X_patients.shape[0],1))\n",
    "y_controls = np.zeros(shape=(X_controls.shape[0],1))\n",
    "\n",
    "X_combined = np.concatenate((X_patients,X_controls),axis=0)\n",
    "Y_combined = np.concatenate((y_patients,y_controls),axis=0)\n",
    "# Make sure that these labels are stored as integer format.\n",
    "Y_combined = Y_combined.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining abnormality in each biomarker\n",
    "* Despite the statistical evidence of group separation...\n",
    "  * Some \"controls\" might have abnormal biomarkers despite appearing normal\n",
    "  * Some patients may have normal values in biomarkers, as they have not yet turned abnormal\n",
    "* What we want to do is to identify normal and abnormal distributions from all of the data\n",
    "  * If we do that, then we can compute the probability that an \"event\" has occurred, $p(data|event)$\n",
    "  * The EBM is a probabilistic framework - there is no magic cutpoint that dichotomises individuals into normal and abnormal\n",
    "  * Thus the EBM can have patients progress to different stages based on cumulative abnormality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the needed functions from the EBM toolbox\n",
    "from kde_ebm.mixture_model import fit_all_kde_models\n",
    "from kde_ebm.plotting import mixture_model_grid, mcmc_uncert_mat, mcmc_trace, stage_histogram\n",
    "from kde_ebm.mcmc import mcmc, parallel_bootstrap, bootstrap_ebm, bootstrap_ebm_fixedMM, bootstrap_ebm_return_mixtures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rather than calling these biomarker 1,2,3,4 we will use some more sensible labels based on when they occur. We also need to tell the EBM the trajectory of abnormality for each biomarker, as some measures are abnormal if they go up and others are abnormal if they go down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Label the biomarkers/events\n",
    "event_labels = ['Early','Early-ish','Late-ish','Late']\n",
    "# The EBM needs to know which direction is abnormal \n",
    "# (1 abnormal means increase, -1 abnorma means decrrease)\n",
    "event_disease_direction_dict = {'Early':1,'Early-ish':1,'Late-ish':1,'Late':1}\n",
    "event_disease_direction = [event_disease_direction_dict[f] for f in event_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mixture models\n",
    "* To identify the probability $p(event|data)$, we will fit each biomarker distribution using mixture models.\n",
    "* Mixture models are a widely-used machine learning method to identify sub-populations from the overall population\n",
    "* The most common approach is a Gaussian mixture model, which assumes each subpopulation can be described by a Gaussian\n",
    "* Here, we will use a non-parametric approach called a Kernel Density Estimator (KDE), which does not make any assumptions of the underlying distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example of a Gaussian Mixture Model\n",
    "![Mixture model](./SUVR_Fit_Hist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kde_mixtures = fit_all_kde_models(\n",
    "    X_combined, Y_combined,\n",
    "    implement_fixed_controls = True,\n",
    "    patholog_dirn_array      = event_disease_direction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize mixture model fits\n",
    "* Despite each biomarker occurring at different times, `p(data|event)` looks roughly the same\n",
    "  * Biomarkers become abnormal at roughly the same levels (0.25 to 0.50), since the range of normal measurements is essentially the same for all four biomarkers\n",
    "* While the biomarkers are all classified as abnormal at the same levels, the number of patients who have a value classified as abnormal is different for each biomarker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#* View the mixture models\n",
    "mixture_model_grid(\n",
    "    X_combined,Y_combined,\n",
    "    kde_mixtures,\n",
    "    score_names=event_labels,\n",
    "    class_names=['Controls','Patients']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uncertainty in the ordering\n",
    "* The model will return the posterior, which is a point estimate of the most probable ordering of events, given the data. \n",
    "* Ideally, we would get the posterior from the ordering with the maximum likelihood\n",
    "* But how can we be sure which ordering has the maximum likelihood if there are many features included in the EBM\n",
    "  * For $N$ features, there are $N!$ possible orderings. \n",
    "  * So our case of four orderings is manageable: there are $4!$ or 24 possible orderings. \n",
    "  * However if we doubled the number of features to eight, that would be $8!$ or 40,320 possible orderings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCMC sampling\n",
    "* The solution to this problem is to use Markov Chain Monte Carlo (MCMC) method. It is a standard approach to  approximate a model posterior when you can't do an exhaustive search.\n",
    "* MCMC generates _random samples from the posterior_ (the full set of possible sequences), and keeps only those sequences that increase the likelihood (ideally towards the maximum).\n",
    "  * In practice, we could get stuck in a local maxima, so we use multiple random initialisations\n",
    "* More information about the MCMC algorithm used in EBM can be found in [Fonteijn _et al._, NeuroImage (2012)](https://doi.org/10.1016/j.neuroimage.2012.01.062)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#* Perform MCMC sequencing and store results in mcmc_samples\n",
    "mcmc_samples = mcmc(X_combined, kde_mixtures)\n",
    "#* Obtaine the maximum Likelihood sequence over all samples\n",
    "seq_ml = mcmc_samples[0].ordering\n",
    "# print('ML sequence: {0}'.format(seq_ml))\n",
    "print('ML order   : %s' % ', '.join([event_labels[k] for k in seq_ml]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# View the ML posterior\n",
    "f,a = mcmc_uncert_mat(mcmc_samples, ml_order=None, score_names=event_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The ordering is as we would expect it to be, the Early one is first, followed by Early-ish, Late-ish, and Late. \n",
    "* This corresponds with how these biomarkers were set to transition from normal to abnormal at 4, 8, 12, and 16 years, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We are going to use the results from the MCMC sampling later, so we are going to save them in a dictionary.\n",
    "ebm_results = {\"mixtures\": kde_mixtures, \"mcmc_samples\": mcmc_samples, \"sequence_ml\": seq_ml}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Positional Variance Diagrams — estimating order uncertainty\n",
    "\n",
    "* The _positional variance diagram_, or PVD, indicates the uncertainty of the resulting orderings.\n",
    "* Uncertainty of these orderings could be due to heterogeneity in the population or noise in the measurements.\n",
    "* The darkness of the box indicates more certainty in the position, fainter boxes indicate less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import some helper functions from a local file.\n",
    "import kde_utils \n",
    "# Get the PVD, the outputs are\n",
    "# a two-dimensional matrix representing the positional variance diagram\n",
    "# and the sequence of the most likely events\n",
    "pvd_ml, seq_ml = kde_utils.extract_pvd(ml_order=seq_ml,samples=mcmc_samples)\n",
    "# Sort the PVD so that the earliest marker is at the top and latest at the bottom\n",
    "reorder_ml = np.argsort(seq_ml)\n",
    "pvd_ml_ = pvd_ml[:][reorder_ml]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Helper variables to make PVD plot nicer\n",
    "labels = event_labels\n",
    "tick_marks_x = np.arange(0,4,1)\n",
    "x_labs = range(1, 5,1)\n",
    "tick_marks_y = np.arange(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(9, 6),sharey=False)\n",
    "ax.imshow(pvd_ml_[:][seq_ml], interpolation='nearest', cmap='Reds') #Plot the PVD\n",
    "ax.set_xticks(tick_marks_x)\n",
    "ax.set_xticklabels(x_labs, rotation=0,fontsize=14) # Make the x labels nicer \n",
    "ax.set_yticks(tick_marks_y+0.0)\n",
    "ax.tick_params(axis='y',color='w')\n",
    "ax.set_yticklabels(labels, rotation=0,rotation_mode='anchor',fontsize=18) # Use biomarker names for y tick labels\n",
    "ax.set_xlabel('Positional Variance', fontsize=24)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Patient staging utility\n",
    "* We can use the ordering generated from the EBM to identify at which point, or stage, each individual is within the disease process. \n",
    "* For more details on staging (see [Young et al, Brain 2014](https://doi.org/10.1093/brain/awu176)) \n",
    "  * Compares biomarkers from each individual  with the model and calculates a `p(event)` vector. \n",
    "  * From this vector, it determines the most likely stage \n",
    "  * We can use this on follow-up timepoints, or from individuals that aren't included in generating the EBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#* Staging\n",
    "#* Maximum-likelihood model stage: could include longitudinal data, including followups not used to train the EBM\n",
    "prob_mat_ml, stages_long_ml, stage_likelihoods_long_ml, stages_long_ml_expected = kde_utils.ebm_staging(\n",
    "    x=X_combined,\n",
    "    mixtures=kde_mixtures,\n",
    "    samples=mcmc_samples\n",
    ")\n",
    "stages_long = stages_long_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have obtained stages for each individual, we will plot a histogram of the stages assigned to each individual (both controls and patients). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.hist([ stages_long[Y_combined==0], stages_long[Y_combined==1]],bins=np.arange(-0.5,num_features+1.5,1))\n",
    "ax.set_ylabel('Number of individuals',fontsize=20)\n",
    "ax.legend(['Controls','Patients'],fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* All of the controls are in stage 0 --> no evidence of disease\n",
    "* The patients are slit evenly across each of the potential disease stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We will again plot the features of each individual with respect to disease time. \n",
    "* **This time** we will colour each individual's points according to their disease stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#* Plot the original data, coloured by stage\n",
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "for k in range(num_features):\n",
    "    scatter = plt.scatter(disease_time,X_combined[Y_combined==1,k],c=stages_long[Y_combined==1],cmap='viridis',label='')\n",
    "#ax.legend(['Stage %i' % k for k in range(num_stages)],loc='center right',bbox_to_anchor=[1.5,0.5])\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper left\", title=\"Stages\")\n",
    "ax.add_artist(legend1)\n",
    "ax.set_xlabel(\"Disease Progression Time\",fontsize=20) \n",
    "ax.set_ylabel(\"Biomarker Value\",fontsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus: Cross-validation\n",
    "\n",
    "The generalisability/robustness of a model can be quantified by **testing** the model on independent data, i.e., data not included when training the model.\n",
    "\n",
    "Cross-validation does this by splitting the available data into train/test sets.\n",
    "\n",
    "### k-fold cross-validation\n",
    "\n",
    "Splitting a dataset into `k` \"folds\" enables the calculation of model performance statistics (e.g., mean, standard deviation) over `k` test sets, using the other `k-1` folds to train the model each time.\n",
    "\n",
    "It is common to use `k=10`, which amounts to using 90% of your data to train and 10% to test.\n",
    "\n",
    "This process can be repeated multiple times using different random partitions (splits) into folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-fold cross-validation\n",
    "![image_kfold_cv](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)\n",
    "\n",
    "By Gufosowa - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=82298768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using k-fold cross-validation of EBM\n",
    "* In the full notebook in the repository, we will use `k=5` folds and repeat the k-fold CV process for 10 random splits.\n",
    "* This fits the EBM 50 times, where four folds are used to build the EBM and one is held out for testing.\n",
    "* If you have time, have a look at the cross-validation code and let us know if you have any questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thanks and good luck with the final task!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "1ca3c52c2c6a741687ac119195f853fd55cbbadb57e664fb666b72dd14734ec5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "rise": {
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
